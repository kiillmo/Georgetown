# Georgetown Portfolio

Welcome to my project portfolio! In this repository, I’ve included a selection of Jupyter notebooks that represent key moments and milestones in my journey into data science and machine learning. Each project highlights a different technique, algorithm, or concept that helped shape my understanding of the field.

## Projects

### 1. Handwritten Digit Recognition with Neural Networks
**File:** [`C2_W2_Assignment.ipynb`](C2_W2_Assignment.ipynb)

This project was one of my earliest ventures into the world of neural networks. The task—recognizing handwritten digits—is a classic introduction to machine learning, and completing it felt like a huge accomplishment. For me, this project was more than just a tutorial; it marked my entry into the field of machine learning, setting the stage for all the more advanced techniques I would explore later.

### 2. Movie Recommendations using Collaborative Filtering
**File:** [`C3_W2_Collaborative_RecSys_Assignment.ipynb`](C3_W2_Collaborative_RecSys_Assignment.ipynb)

This notebook focuses on implementing collaborative filtering to recommend movies to users. It’s meaningful to me on a personal level, as it connects directly to a question that first sparked my interest in data science. In my Statement of Purpose, I mentioned that my early success in e-commerce led me to wonder: “How was Facebook able to target an audience so effectively for my products?”
The recommendation algorithms, which identify similar users or items to make tailored suggestions, provided a glimpse into the kind of techniques that power the lookalike audiences used in social media ad targeting. Working through this project helped me realize that I’d reached a stage in my skill development where concepts that once felt out of reach were now understandable and implementable.

### 3. Lunar Lander with Reinforcement Learning
**File:** [`C3_W3_A1_Assignment.ipynb`](C3_W3_A1_Assignment.ipynb)

This is perhaps my favorite project. I trained a lunar lander agent using reinforcement learning techniques. The lander would initially fly around aimlessly and crash, but eventually it learned to succcessfully land in the target area. I vividly remember setting the code to run and then stepping away to watch a Lakers game with my brother. About 45 minutes later, I remember returning to a successfully trained agent. I was bursting with excitement but when I showed it to my brother he was thoroughly unimpressed. I blame that on the Lakers losing. Despite that, the moment captured the joy I find in data science: witnessing tangible progress in something that once seemed impossible.

### 4. Revisiting My E-commerce Data (Xmas Everything)
**File:** [`Xmas_Everything_Data.ipynb`](Xmas_Everything_Data.ipynb)

In this notebook, I revisited the data from my “Xmas Everything” store. Years ago, I relied mostly on basic analytics. Now, equipped with a broader data science toolkit, I reanalyze those metrics with more advanced techniques. It was both nostalgic and revelatory to see how far I’ve come. I hope this project demonstrates not only my current skills, but also my growth and adaptability over time.

### 5. Local LLM utilizing RAG

A few weeks ago my manager informed me that our company was looking to implement AI at the company and were receiving quotes from vendors to build an in-house LLM. I thought it would be interesting to present to them on how LLMs work, and even provide them with alternatives to what these vendors are offering. A meeting is in the works for me to show them everything from custom GPTs on closed-sourced websites to locally run LLMs using open-sourced models and even a server run model using AWS' Bedrock. Attached to this GitHub will be a very basic initial look at the locally run LLM that I built. It runs on llama 3.2 3B and utilizes RAG to retrieve data about the ASI Methodology, a process improvement methodology developed by me and my colleague, Michael. On the front end, streamlit was used to provide a user-friendly interface for queries.
---

## Closing Thoughts

These projects collectively illustrate my evolution as a data scientist. From foundational neural networks to recommendation systems, from reinforcement learning to applying refined skills to my own past work, each step marked a deeper understanding and a new layer of insight. I’m proud of how far I’ve come and eager for what lies ahead.

Thank you for exploring my work!
